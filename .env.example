# Google Generative AI Key for Gemini models
# Get your key from https://ai.google.dev/
# Use the AI_CODE_REVIEW prefix for all environment variables (recommended)
AI_CODE_REVIEW_GOOGLE_API_KEY=your_google_api_key_here

# Legacy environment variables (still supported for backward compatibility)
# CODE_REVIEW_GOOGLE_API_KEY=your_google_api_key_here
# GOOGLE_GENERATIVE_AI_KEY=your_google_api_key_here

# OpenRouter API Key for Claude, GPT-4, and other models
# Get your key from https://openrouter.ai/
AI_CODE_REVIEW_OPENROUTER_API_KEY=your_openrouter_api_key_here

# Anthropic API Key for direct access to Claude models
# Get your key from https://console.anthropic.com/
AI_CODE_REVIEW_ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key for direct access to GPT models
# Get your key from https://platform.openai.com/
AI_CODE_REVIEW_OPENAI_API_KEY=your_openai_api_key_here

# Context files for code review (comma-separated list of file paths relative to project root)
# Example: README.md,docs/architecture.md,PROJECT.md
AI_CODE_REVIEW_CONTEXT=PROJECT.md

# Model configuration
# Specify which model to use for code reviews using the format adapter:model
# Each adapter requires its corresponding API key (e.g., openai:gpt-4o requires AI_CODE_REVIEW_OPENAI_API_KEY)

# Default model
AI_CODE_REVIEW_MODEL=gemini:gemini-1.5-pro

# Semantic chunking configuration
# Enable semantic chunking for intelligent code analysis (default: true)
# Set to 'false' to disable semantic chunking and use traditional token-based chunking
AI_CODE_REVIEW_ENABLE_SEMANTIC_CHUNKING=true

# GitHub Projects integration
# GitHub API token for accessing GitHub Projects
GITHUB_TOKEN=your_github_token_here

# GitHub Project ID (required if GITHUB_PROJECT_NUMBER not provided)
# GITHUB_PROJECT_ID=your_project_id_here

# GitHub Project number (required if GITHUB_PROJECT_ID not provided)
# GITHUB_PROJECT_NUMBER=1

# GitHub owner (default: 'bobmatnyc')
# GITHUB_OWNER=your_github_username

# Supported Gemini models:
# gemini:gemini-2.5-pro         - Latest model with improved capabilities (uses preview version)
# gemini:gemini-2.5-pro-preview - Latest preview model
# gemini:gemini-2.5-pro-exp     - Experimental version of 2.5 Pro
# gemini:gemini-2.0-flash       - Balanced performance and quality
# gemini:gemini-2.0-flash-lite  - Lighter version of 2.0 Flash
# gemini:gemini-1.5-pro         - Recommended for most code reviews
# gemini:gemini-1.5-flash       - Faster but less detailed reviews
# gemini:gemini-1.5-flash-8b    - Smallest and fastest 1.5 model

# IMPORTANT: The tool will NOT automatically fall back to other models if the specified model is unavailable.
# If you encounter a "model not found" error, please check that you're using a valid model name.
# You can verify available models at: https://ai.google.dev/models/gemini

# Supported OpenRouter models:
# openrouter:anthropic/claude-3-opus     - Highest quality, most detailed reviews
# openrouter:anthropic/claude-3-sonnet   - Good balance of quality and speed
# openrouter:anthropic/claude-3-haiku    - Fast, efficient reviews
# openrouter:openai/gpt-4-turbo          - Strong performance on complex code
# openrouter:openai/gpt-4o               - Latest OpenAI model
# openrouter:google/gemini-1.5-pro       - Google's model via OpenRouter

# Supported Anthropic models (requires AI_CODE_REVIEW_ANTHROPIC_API_KEY):
# anthropic:claude-3-opus      - Highest quality, most detailed reviews
# anthropic:claude-3-sonnet    - Good balance of quality and speed
# anthropic:claude-3-haiku     - Fast, efficient reviews

# Supported OpenAI models (requires AI_CODE_REVIEW_OPENAI_API_KEY):
# openai:gpt-4o                         - Latest OpenAI model, best performance
# openai:gpt-4-turbo                    - Strong performance on complex code
# openai:gpt-4                          - Reliable performance for detailed reviews
# openai:gpt-3.5-turbo                  - Fast, cost-effective reviews

# Logging configuration
# Controls the verbosity of logging output
# Supported values: debug, info, warn, error, none
AI_CODE_REVIEW_LOG_LEVEL=info
